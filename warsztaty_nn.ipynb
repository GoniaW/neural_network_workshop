{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "![](img/shutterstock_175625024.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ogólnie o uczeniu maszynowym i sieciach neuronowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dlaczego?**  \n",
    "* problemy które ciężko opisać klasycznymi algorytmami  \n",
    "* problemy które są łatwe dla ludzi, ale nie znamy sposobu w jaki nasz mózg sobie z nimi radzi\n",
    "* problemy dla których rozwiązanie ciągle się zmienia  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Jak?**  \n",
    "* zamiast pisać gotowe rozwiązanie - zbieramy dane z rozwiązaniem problemu  \n",
    "* zadaniem algorytmu uczenia maszynowego jest \"nauczenie się\", które własności/cechy mają wpływ na odpowiedź\n",
    "* dobry algorytm powinien nauczyć się ogólnych reguł, zamiast uczyć się \"na pamięć\" zbioru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Co?**  \n",
    "* rozpoznawanie wzorców  \n",
    "* detekcja anomalii  \n",
    "* przewidywanie - problem klasyfikacji/regresji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sieci neuronowe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bardzo ogólne pojęcie obejmujące szeroką klasę algorytmów\n",
    "* wzorowane na budowie ludzkiego mózgu  \n",
    "* każdy neuron zbiera sygnały od innych neuronów, i w zależności od kombinacji sygnałów aktywuje się lub nie\n",
    "* różne struktury w mózgu mają różny cel - rozpoznawanie mowy, analiza obrazu, itp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/neuron.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sztuczne sieci neuronowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/artificial_neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* złożone z grup (warstw) neuronów komunikujących się ze sobą  \n",
    "* najczęściej stosowane neurony są postaci jak na powyższej grafice - suma neuronów wejściowych przetransformowana jakąś funkcją  \n",
    "* w przeciwieństwie do prawdziwych neuronów, nie są aktywowane tylko zero-jedynkowo, ale mogą też przyjmować wartości rzeczywiste  \n",
    "* przykładowe sztuczne neurony:\n",
    "    * liniowy: $y = \\sum x_iw_i + b$\n",
    "    * ReLU: $y = max(0, \\sum x_iw_i + b)$\n",
    "    * liniowy: $z = \\sum x_iw_i + b, y = \\frac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ann.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Proste przykłady"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Na początek wygenerujmy dane z najprostszego modelu, tzn liniowego.\n",
    "Zakładamy, że $y$ jest liniową transformacją $X = [x_1, x_2]$, tzn:  \n",
    "\n",
    "\n",
    "$$ y = f(x_1, x_2) = XW + b = x_1 \\cdot w_1 + x_2 \\cdot w_2 + b$$\n",
    "\n",
    "\n",
    "$W = [w_1, w_2]$ jest tutaj macierzą (wektorem) wag, a $b$ - wyrazem wolnym.\n",
    "\n",
    "Zadaniem naszego algorytmu będzie poprawne znalezienie wartości $W$ i $b$ na podstawie danych.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### generacja danych \n",
    "coefs = np.array([4, -2])\n",
    "b = -5\n",
    "X = np.random.uniform(low=-4, high=4, size = (1000,2))\n",
    "y = X.dot(coefs) + b\n",
    "\n",
    "# dodanie czynnika losowego\n",
    "y += np.random.uniform(low=-1, high=1, size = y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(x=X[:, 0], y=X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Jak wygląda proces uczenia modelu?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw musimy zdefiniować nasz model. W tym przypadku optymalne będzie tutaj użycie neuronu liniowego przyjmującego na wejściu dwie wartości:  \n",
    "\n",
    "\n",
    "$$ \\hat{y} = \\sum_{i} x_i w_i + b $$  \n",
    "\n",
    "Następnie będziemy pokazywać modelowi po jednej obserwacji, i dla każdej z nich sprawdzać, czy jego wartość wyjściowa pokrywa się z prawdziwą wartością, czy nie. Na podstawie tego nastąpi mała aktualizacja wag $w_1$ i $w_2$.  \n",
    "\n",
    "Tą procedurę będziemy powtarzać aż do uzyskania zadowalającego nas wyniku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby nasz model był w stanie się czegokolwiek nauczyć, musimy zdefiniować jakąś miarę błędu, którą będziemy starali się zminimalizować.  \n",
    "Dobrą miarą będzie tzw. błąd średniokwadratowy:\n",
    "\n",
    "$$ MSE = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "gdzie $y_i$ to prawdziwa wartość w $i$-tej obserwacji, a $\\hat{y}_i$ to nasze przybliżenie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym momencie nasz problem sprowadza się do prostego problemu optymalizacji:  \n",
    "Jak dobrać współczynniki $w_1$ i $w_2$ tak, aby zmniejszyć błąd dla danej obserwacji?\n",
    "\n",
    "Jak to w problemach optymalizacyjnych, posłużymy się pochodną.  \n",
    "\n",
    "Załóżmy, że mamy dany wektor wejściowy $[x_1, x_2]$, prawdziwą wartość naszej funkcji $y$, wektor wag $[w_1, w_2]$ oraz wyraz wolny $b$.  \n",
    "\n",
    "Zgodnie z budową neuronu, nasza predykcja ma wartość  \n",
    "\n",
    "$$ \\hat{y} = x_1 w_1 + x_2 w_2 + b $$\n",
    "\n",
    "Podstawiając to do wzoru na MSE dostajemy  \n",
    "\n",
    "$$ MSE = L(y) = (y - \\hat{y})^2 = (y - x_1 w_1 + x_2 w_2 + b)^2 $$\n",
    "\n",
    "Chcemy dopasować nasze parametry $w_1$ i $w_2$ tak, aby zminimalizować wartość funkcji $L(y)$. Musimy więć policzyć pochodne $\\frac{\\partial L}{\\partial w_1}$, $\\frac{\\partial L}{\\partial w_2}$ i $\\frac{\\partial L}{\\partial b}$.  \n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w_1} = - 2 \\cdot (y - x_1 w_1 + x_2 w_2 + b) \\cdot x_1 $$  \n",
    "$$ \\frac{\\partial L}{\\partial w_2} = - 2 \\cdot (y - x_1 w_1 + x_2 w_2 + b) \\cdot x_2 $$  \n",
    "$$ \\frac{\\partial L}{\\partial b} = - 2 \\cdot (y - x_1 w_1 + x_2 w_2 + b) $$  \n",
    "\n",
    "W celu minimalizacji funkcji chcielibyśmy \"iść\" w kierunku przeciwnym do pochodnej.  \n",
    "Proces obliczania kolejnych pochodnych nazywamy **propagacją wsteczną** (*backpropagation*).  \n",
    "Cały algorytm optymalizacji wag zwie się **SGD** (*stochastic gradient descent*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model liniowy z uczeniem online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = 0\n",
    "w_2 = 0\n",
    "b_hat = 0\n",
    "step_size = 0.01\n",
    "N_STEPS = 2000\n",
    "for i in range(N_STEPS):\n",
    "    index = i % X.shape[0]\n",
    "    training_x = X[index]\n",
    "    training_y = y[index]\n",
    "    prediction = training_x[0]*w_1 + training_x[1]*w_2 + b_hat\n",
    "    difference =  training_y - prediction\n",
    "    loss = difference ** 2\n",
    "    \n",
    "    dw_1 = -2 * difference * training_x[0] \n",
    "    dw_2 = -2 * difference * training_x[1]\n",
    "    db = -2 * difference \n",
    "    \n",
    "    w_1 -= dw_1 * step_size\n",
    "    w_2 -= dw_2 * step_size\n",
    "    b_hat -= db * step_size\n",
    "    \n",
    "    # TODO: niech co 100 iteracji uczenia wypisze się średnie MSE (loss) na zbiorze treningowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = X.dot(np.array([w_1, w_2])) + b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean((predictions - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciekawostka: tak wygląda rozkład błędu w naszej przestrzeni parametrów $w_1$ i $w_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_mse_on_dataset(X, true_y, W, b):\n",
    "    predictions = X.dot(W) + b\n",
    "    return np.mean((predictions - true_y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w_1s = np.linspace(start=-8, stop=8, num=100)\n",
    "w_2s = np.linspace(start=-8, stop=8, num=100)\n",
    "w_s = np.array([[w_1, w_2] for w_1 in w_1s for w_2 in w_2s])\n",
    "errors = np.zeros(shape = w_s.shape[0])\n",
    "for i in range(w_s.shape[0]):\n",
    "    errors[i] = calculate_mse_on_dataset(X, y, w_s[i], b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(x=w_s[:, 0], y=w_s[:, 1], c=errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model liniowy z uczeniem w mini-batch'ach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktualizacja po jednej obserwacji może być w praktyce mało wydajna obliczeniowo, oraz obarczona sporym błędem spowodowanym dużą zmiennością między obserwacjami. Dlatego w praktyce stosuje się tzw. _mini-batch learning_ - funkcję błędu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = np.array([4, -2])\n",
    "b = -5\n",
    "X = np.random.uniform(low=-4, high=4, size = (1000,2))\n",
    "y = X.dot(coefs) + b\n",
    "\n",
    "# dodanie czynnika losowego\n",
    "y += np.random.uniform(low=-2, high=2, size = y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = 0\n",
    "w_2 = 0\n",
    "b_hat = 0\n",
    "step_size = 0.01\n",
    "N_STEPS = 200\n",
    "BATCH_SIZE = 32\n",
    "for i in range(N_STEPS):\n",
    "    indexes = np.random.choice(range(X.shape[0]), size=BATCH_SIZE, replace=False)\n",
    "    training_x = X[indexes]\n",
    "    training_y = y[indexes]\n",
    "    \n",
    "    predictions = np.array([x_1*w_1 + x_2*w_2 + b_hat for (x_1, x_2) in training_x])\n",
    "    difference =  training_y - predictions\n",
    "    loss = np.mean(difference ** 2)\n",
    "    \n",
    "    # TODO: przelicz czy na pewno pochodna jest ok ;)\n",
    "    \n",
    "    dw_1 = -2 * np.mean(difference * training_x[:, 0])\n",
    "    dw_2 = -2 * np.mean(difference * training_x[:, 1])\n",
    "    db = -2 * np.mean(difference) \n",
    "    \n",
    "    w_1 -= dw_1 * step_size\n",
    "    w_2 -= dw_2 * step_size\n",
    "    b_hat -= db * step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = X.dot(np.array([w_1, w_2])) + b_hat\n",
    "np.mean((predictions - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Notacja macierzowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy większej ilości wag rozpisywanie każdej pochodnej z osobna byłoby uciążliwe. Dlatego wygodniej jest stosować notację macierzową.  \n",
    "\n",
    "Niech $X$ będzie macierzą danych o wymiarach $n \\times m$, $W$ będzie macierzą wag $m \\times h$ a $b$ będzie macierzą wyrazów wolnych $n \\times h$. Wtedy nasz model można zapisać jako \n",
    "\n",
    "$$ Y = XW + b $$\n",
    "\n",
    "$Y$ jest teraz macierzą zawierającą aktywacje $h$ neuronów dla każdej z $n$ obserwacji w mini-batchu. **Uwaga**: macierz $b$ jest podstępna - każdy wiersz zawiera te same wartości (zastanów się dlaczego)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby uciec trochę od oklepanego już problemu regresji linowej, zmienimy trochę naturę problemu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs_1 = np.array([4, -2])\n",
    "b_1 = -5\n",
    "coefs_2 = np.array([-3, -4])\n",
    "b_2 =  1\n",
    "\n",
    "X = np.random.uniform(low=-4, high=4, size = (1000,2))\n",
    "\n",
    "Y = np.where(\n",
    "    X.dot(coefs_1) + b_1 > X.dot(coefs_2) + b_2 + np.random.uniform(low=-2, high=2, size = y.shape),\n",
    "    1, \n",
    "    0\n",
    ").reshape(1000, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(x=X[:, 0], y=X[:, 1], c=Y.reshape(1000,))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tym razem naszym problemem jest klasyfikacja. Nasz poprzedni model zwracał nam wartość rzeczywistą, której nie jesteśmy w stanie przełożyć bezpośrednio na przynależność do jednej z dwóch klas. Wprowadzimy więc funkcję aktywacji zwaną sigmoid: \n",
    "\n",
    "$$ S (x) = \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "Dostajemy więc przełożenie wartości rzeczywistej na wartość z przedziału $[0, 1]$\n",
    "\n",
    "Mając już odpowiednią formę wyjścia z naszej sieci, potrzebujemy jeszcze funkcji straty - czyli informacji dla modelu, kiedy dokonał właściwej decyzji, a kiedy nie.  \n",
    "\n",
    "\n",
    "Będziemy optymalizować funkcję straty \n",
    "$$ L(y, \\hat{y}) = -\\frac{1}{N} \\sum_{n} y_{n}\\ln{\\hat{y_{n}}} +  (1-y_{n})\\ln{(1-\\hat{y_{n}})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jak wygląda nasz model w konwencji macierzowej? **  \n",
    "$H = XW + b$ - tutaj dokonujemy liniowej transformacji macierzy wejściowej  \n",
    "$ \\hat{Y} = S(H) $ - tutaj przekształcamy wyjście z poprzedniej operacji funkcją sigmoid. Przez $\\sigma(H)$ rozumiemy tutaj macierz powstałą z zaaplikowania funkcji sigmoid do każdego elementu macierzy $H$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jak przełożyć różniczkowanie na macierze?**  \n",
    "Okazuje się, że naginając trochę konwencje zapisu, możemy korzystać z umownych operatorach różniczkowania macierzy. Tutaj omówię to bardzo pobieżnie - dla chętnych lektura: http://cs231n.stanford.edu/vecDerivs.pdf  \n",
    "\n",
    "Zapiszmy naszą funkcję straty w postaci wektora:  \n",
    "$$ L(Y, \\hat{Y}) = Y \\circ \\ln{\\hat{Y}} + (1-Y) \\circ \\ln{(1-\\hat{Y})} $$\n",
    "\n",
    "Symbol $\\circ$ oznacza tutaj mnożenie po elementach.  \n",
    "Wynikowy wektor L jest wektorem wartości funkcji straty dla każdej obserwacji.  \n",
    "\n",
    "To co nas interesuje, to w jak wartości wag $W$ i $b$ wpływają na naszą funkcję straty $L$. Przekładając to na język matematyczny, interesują nas pochodne $\\frac{\\partial L}{\\partial W} $ i $\\frac{\\partial L}{\\partial b} $  \n",
    "Aby je policzyć, skorzystamy z reguły łancuchowej:\n",
    "$$ \\frac{\\partial L}{\\partial W} = \n",
    "\\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \n",
    "\\frac{\\partial \\hat{Y}}{\\partial H} \\cdot \n",
    "\\frac{\\partial H}{\\partial W} $$\n",
    "\n",
    "Ponieważ operujemy na macierzach, wynikowe pochodne też będą macierzami i musimy ustalić, które operacje mnożenia będą operacjami mnożenia macierzowego ($\\cdot$), a które będą wynikały z mnożenia po elementach ($\\circ$).  \n",
    "\n",
    "Warto zauważyć, że niektóre przekształcenia zmieniają rozmiar macierzy (na przykład $H = XW + b$), a inne nie ($ \\hat{Y} = S(H) $). Stąd łatwo się domyślić, kiedy musimy używać każdej z operacji. Ostatecznie mamy więc wzór   \n",
    "$$ \\frac{\\partial L}{\\partial W} = \n",
    "\\frac{\\partial L}{\\partial \\hat{Y}} \\circ \n",
    "\\frac{\\partial \\hat{Y}}{\\partial H} \\cdot \n",
    "\\frac{\\partial H}{\\partial W} $$  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poszczególne pochodne wyglądają następująco:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial \\hat{Y}} = \\frac{Y}{\\hat{Y}} - \\frac{1-Y}{1-\\hat{Y}}$$  \n",
    "$$ \\frac{\\partial \\hat{Y}}{\\partial H} = S(H) \\circ (1-S(H))$$\n",
    "$$ \\frac{\\partial H}{\\partial W} = X $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    ################\n",
    "    # TODO: zaimplementuj funkcję sigmoid tak, aby działała na numpy arrayach\n",
    "    ################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 2 # number of inputs\n",
    "K = 1 # number of outputs\n",
    "W = np.zeros((D,K))\n",
    "b = np.zeros((1,K))\n",
    "\n",
    "# parametry \n",
    "step_size = 1e-0\n",
    "reg = 1e-2\n",
    "\n",
    "num_examples = X.shape[0]\n",
    "\n",
    "for i in range(300):  \n",
    "    # obliczamy scory oraz przynależności do klas przy aktualnych wagach\n",
    "    scores = np.dot(X, W) + b \n",
    "    \n",
    "    probs = sigmoid(scores)\n",
    "\n",
    "    # obliczamy funkcję straty dla aktualnej predykcji\n",
    "    \n",
    "    loss = Y * np.log(probs) - (1-Y)*(np.log(1-probs))\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(\"iteration %d: loss %f\" % (i, np.mean(loss)))\n",
    "    \n",
    "    # wyliczamy gradient funkcji straty\n",
    "    dL_dprobs = 1/num_examples * (Y-probs) # 1000x1\n",
    "    dprobs_dH = probs *(1-probs) # 1000x1\n",
    "    \n",
    "    dL_dH = dL_dprobs * dprobs_dH # 1000x1\n",
    "    \n",
    "    # propagacja wsteczna\n",
    "    dL_dW = np.dot(X.T, dL_dH) # 2x1\n",
    "    dL_db = np.sum(dL_dH, axis=0, keepdims=True) # 1x1\n",
    "    \n",
    "    # aktualizujemy parametry\n",
    "    W += -step_size * dL_dW\n",
    "    b += -step_size * dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.dot(X, W) + b \n",
    "probs = sigmoid(scores)\n",
    "preds = (probs > 0.5).astype(int).reshape(1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(x=X[:, 0], y=X[:, 1], c=preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Warstwy ukryte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Póki co rozwiązywaliśmy problemy liniowe - zwykła transformacja liniowa pozwalała osiągnąć bardzo dobre wyniki. Co jednak się stanie jeśli zbiór danych nie będzie tak prosty?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "points_per_class = 200\n",
    "X = np.zeros((points_per_class*n_classes, 2))\n",
    "Y = np.zeros((points_per_class*n_classes, 3), dtype=int)\n",
    "for i in range(n_classes):\n",
    "    idx = range(points_per_class*i,points_per_class*(i+1))\n",
    "    \n",
    "    r = i + np.random.random(points_per_class)* 0.5 # \n",
    "    t = np.random.random(points_per_class) *2* np.pi\n",
    "    \n",
    "    X[idx] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "    Y[idx, i] = 1 # TODO: spojrzeć jak wygląda zakodowanie klas \n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=np.argmax(Y, axis=1), s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy, w danych mamy trzy klasy - zadaniem algorytmu będzie zaklasyfikowanie obserwacji do jednej z klas. Potrzebujemy zatem dwóch rzeczy: funkcji aktywacyjnej, która zamieni 3-elementowe wyjście z neuronu na wektor trzech prawdopodobieństw sumujących się do 1, oraz funkcji straty, która odpowiednio \"ukarze\" algorytm za złe predykcje.  \n",
    "\n",
    "Funkcją aktywacji której użyjemy jest *softmax*. Przyjmuje ona na wejściu wektor $a$ i zwraca również wektor, którego elementy są dane wzorem:\n",
    "\n",
    "$$\\sigma (a_j) = \\frac{\\exp{a_j}}{\\sum_{i = 1}^{k} \\exp{a_i}}$$  \n",
    "\n",
    "Naturalną funkcją straty jest tutaj rozszerzenie *log-lossa* na wiele klas. Dla pojedynczej obserwacji wygląda ona następująco:\n",
    "\n",
    "$$ L(y, \\hat{y}) = \\sum_{k=1}^{K} y_k \\cdot \\ln(\\hat{y}_k) $$  \n",
    "gdzie $y$ i $\\hat{y}$ to odpowiednio wektor prawdziwych przynależności do klas i wektor prawdopodobieństw zwróconych przez model.  \n",
    "\n",
    "**Nasz model wygląda więc następujaco:**  \n",
    "$H = XW + b$ - tutaj dokonujemy liniowej transformacji macierzy wejściowej  \n",
    "$ \\hat{Y} = \\sigma(H) $ - przekształcenie wyjścia z poprzedniej sieci funkcją sigmoid $H$  \n",
    "\n",
    "Tak samo jak wcześniej, skorzystamy z reguły łańcuchowej w celu policzenia odpowiednich pochodnych. Aby uprościć obliczenia, można obliczyć pochodną funkcji $L$ od razu po wartościach $H$:  \n",
    "\n",
    "Przez $h$ oznaczmy wiersz z macierzy $H$. W kolejnym kroku dokonujemy transformacji $\\sigma(H)$, więc możemy napisać że $\\hat{y}_j = \\frac{\\exp{h_j}}{\\sum_{i = 1}^{k} \\exp{h_i}}$. Następnie za pomocą otrzymanych wartości liczymy funkcję straty $L(y, \\hat{y})$.  \n",
    "\n",
    "Po dość prostych obliczeniach dostajemy \n",
    "$$\\frac{\\partial L}{\\partial h_j} = \\hat{y_j} - y_j$$  \n",
    "\n",
    "**TODO: przeliczyć w domu i sprawdzić czy faktycznie tak jest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "K = 3\n",
    "W = np.zeros((D,K))\n",
    "b = np.zeros((1,K))\n",
    "\n",
    "# parametry \n",
    "step_size = 1e-4\n",
    "reg = 1e-2\n",
    "\n",
    "num_examples = X.shape[0]\n",
    "\n",
    "for i in range(200):  \n",
    "    # obliczamy scory oraz przynależności do klas przy aktualnych wagach\n",
    "    scores = np.dot(X, W) + b \n",
    "    \n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "    # obliczamy funkcję straty dla aktualnej iteracji\n",
    "    loss_matrix = -np.log(probs) * Y\n",
    "    mean_loss = np.mean(loss_matrix)\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(\"iteration %d: loss %f\" % (i, mean_loss))\n",
    "\n",
    "    # wyliczamy gradient funkcji straty\n",
    "    dL_dH = probs - Y\n",
    "    \n",
    "    # propagacja wsteczna\n",
    "    \n",
    "    dW = np.dot(X.T, dL_dH)\n",
    "    db = np.sum(dL_dH, axis=0, keepdims=True)\n",
    "\n",
    "    # dodajemy jeszcze wpływ regularyzacji do gradientu wag\n",
    "    dW += reg * W\n",
    "\n",
    "    # aktualizujemy parametry\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.dot(X, W) + b\n",
    "predicted_class = np.argmax(scores, axis=1) # nie musimy wyliczać konkretnych prawdopodobienstw - exp jest funkcją rosnącą\n",
    "print('overall accuracy: %.2f' % (np.mean(predicted_class == np.argmax(Y, 1))))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=predicted_class, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać ewidentnie, że model nie jest w stanie dopasować się do tego zbioru. Spróbujmy zatem dodać dodatkową warstwę między wejściem a wyjściem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jedna warstwa ukryta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "K = 3\n",
    "h = 12 # size of hidden layer\n",
    "W = np.zeros((D,h)) \n",
    "b = np.zeros((1,h))\n",
    "W2 = np.zeros((h,K)) \n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# parametry \n",
    "step_size = 1e-2\n",
    "reg = 5e-2 # regularization strength\n",
    "\n",
    "\n",
    "num_examples = X.shape[0]\n",
    "for i in range(100):  \n",
    "    # obliczamy scory oraz przynależności do klas przy aktualnych wagach\n",
    "    hidden_layer = np.maximum(0, np.dot(X, W) + b) # warstwa ukryta - stosujemy funkcję aktywacyjną ReLU\n",
    "    scores = np.dot(hidden_layer, W2) + b2 # warstwa końcowa\n",
    "\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "    # obliczamy funkcję straty dla aktualnej predykcji\n",
    "    loss_matrix = -np.log(probs) * Y\n",
    "    mean_loss = np.mean(loss_matrix)\n",
    "    if i % 20 == 0:\n",
    "        print(\"iteration %d: loss %f\" % (i, mean_loss))\n",
    "\n",
    "    # wyliczamy gradient funkcji straty\n",
    "    dL_dH = probs - Y\n",
    "    #dL_dH /= num_examples\n",
    "    \n",
    "    # it's backpropagation time!\n",
    "    # najpierw badamy wpływ wag i stałej w ostatniej warstwie\n",
    "    dW2 = np.dot(hidden_layer.T, dL_dH)\n",
    "    db2 = np.sum(dL_dH, axis=0, keepdims=True)\n",
    "    \n",
    "    # następnie liczymy gradient dla wartości w warstwie ukrytej\n",
    "    dhidden = np.dot(dL_dH, W2.T)\n",
    "    # pamietamy o uwzględnieniu pochodnej funkcji aktywacyjnej - na szczęście jest dość prosta\n",
    "    dhidden[hidden_layer <= 0] = 0\n",
    "    # na koniec dostajemy gradienty dla pierwszej warstwy\n",
    "    dW = np.dot(X.T, dhidden)\n",
    "    db = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "    # dodajemy jeszcze wpływ regularyzacji do gradientu wag\n",
    "    dW2 += reg * W2\n",
    "    dW += reg * W\n",
    "\n",
    "    # aktualizujemy parametry\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db\n",
    "    W2 += -step_size * dW2\n",
    "    b2 += -step_size * db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieć się w ogóle nie uczy. **TODO: burza mózgów - dlaczego?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = np.dot(X, W) + b\n",
    "scores = np.dot(hidden, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1) # nie musimy wyliczać konkretnych prawdopodobienstw - exp jest funkcją rosnącą\n",
    "print('overall accuracy: %.2f' % (np.mean(predicted_class == np.argmax(Y, 1))))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=predicted_class, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "#miejsce na naprawienie błędu\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wciąż nie ma poprawy - dlaczego? **TODO: zastanowić się czemu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warstwa ukryta z aktywacją relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    \"\"\"\n",
    "    Only for numpy arrays!!\n",
    "    \"\"\"\n",
    "    return np.maximum(x, 0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 2\n",
    "K = 3\n",
    "h = 15 # size of hidden layer\n",
    "W = 1 * np.random.randn(D,h) #np.zeros((D,K)) \n",
    "b = np.zeros((1,h))\n",
    "W2 = 1 * np.random.randn(h,K) #np.zeros((D,K)) \n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# parametry \n",
    "step_size = 1e-1\n",
    "reg = 5e-2 # regularization strength\n",
    "\n",
    "\n",
    "num_examples = X.shape[0]\n",
    "for i in range(200):  \n",
    "    # obliczamy scory oraz przynależności do klas przy aktualnych wagach\n",
    "    hidden_layer = np.maximum(0, np.dot(X, W) + b) # warstwa ukryta - stosujemy funkcję aktywacyjną ReLU\n",
    "    hidden_activation = relu(hidden_layer)\n",
    "    scores = np.dot(hidden_activation, W2) + b2 # warstwa końcowa\n",
    "\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "    # obliczamy funkcję straty dla aktualnej predykcji\n",
    "    loss_matrix = -np.log(probs) * Y\n",
    "    mean_loss = np.mean(loss_matrix)\n",
    "    if i % 20 == 0:\n",
    "        print(\"iteration %d: loss %f\" % (i, mean_loss))\n",
    "\n",
    "    # wyliczamy gradient funkcji straty\n",
    "    dL_dH = probs - Y\n",
    "    dL_dH /= num_examples\n",
    "    \n",
    "    # it's backpropagation time!\n",
    "    # najpierw badamy wpływ wag i stałej w ostatniej warstwie\n",
    "    dW2 = np.dot(hidden_layer.T, dL_dH)\n",
    "    db2 = np.sum(dL_dH, axis=0, keepdims=True)\n",
    "    \n",
    "    # następnie liczymy gradient dla wartości w warstwie ukrytej\n",
    "    dhidden = np.dot(dL_dH, W2.T)\n",
    "    # pamietamy o uwzględnieniu pochodnej funkcji aktywacyjnej ReLu \n",
    "    dhidden[hidden_layer <= 0] = 0\n",
    "    \n",
    "    # na koniec dostajemy gradienty dla pierwszej warstwy\n",
    "    dW = np.dot(X.T, dhidden)\n",
    "    db = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "    # dodajemy jeszcze wpływ regularyzacji do gradientu wag\n",
    "    dW2 += reg * W2\n",
    "    dW += reg * W\n",
    "\n",
    "    # aktualizujemy parametry\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db\n",
    "    W2 += -step_size * dW2\n",
    "    b2 += -step_size * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = np.dot(X, W) + b\n",
    "hidden = relu(hidden)\n",
    "scores = np.dot(hidden, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1) # nie musimy wyliczać konkretnych prawdopodobienstw - exp jest funkcją rosnącą\n",
    "print('overall accuracy: %.2f' % (np.mean(predicted_class == np.argmax(Y, 1))))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=predicted_class, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Uff - teraz działa**.  \n",
    "\n",
    "Tutaj warto wspomnieć, że sieci neuronowe są uniwersalnymi aproksymatorami - to jest, dla dowolnej funkcji istnieje konkretna sieć neuronowa (przez sieć rozumiemy tutaj zarówno jej architekturę, jak i konkretne wagi) która dowolnie dobrze jest w stanie przybliżyć tą funkcję.  \n",
    "Jeśli więc wiemy, że istnieje funkcja która z naszego $X$ daje nam $y$, to istnieje też sieć neuronowa któa będzie tą funkcję imitować. To, co realizujemy podczas uczenia (i projektowania sieci) jest poszukiwaniem tej funkcji. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Wszystko fajnie, ale po co się męczyć? Z pomocą przychodzi pakiet `keras`.  \n",
    "**TODO: obowiązkowo odwiedzić** https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstawowym obiektem z którego będziemy korzystać jest `Sequential`. Pozwala on na budowę podstawowych modelu, w których każda warstwa łączy się z jedną poprzednią. W zupełności wystarczy to do naszych zastosowań. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz kolej na dodawanie do modelu kolejnych warstw. Na razie będziemy korzystać z warstw `Dense` i `Activation`. Warstwy możecie zaimportować z modułu keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas na zbudowanie modelu. Stwórzmy model analogiczny do tego z poprzedniego kroku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# najpierw inicjalizujemy pusty model\n",
    "model = Sequential()\n",
    "# następnie dodajemy warstwy w kolejności w jakiej mają znaleźć się w sieci\n",
    "# w pierwszej warstwie modelu musimy powiedzieć jakiego rozmiaru będzie wejście. \n",
    "# Dalej nie musimy już tego robić, keras sam się domyśli\n",
    "\n",
    "model.add(Dense(15, input_dim=2)) \n",
    "model.add(Activation('relu')) # dodanie funkcji aktywacyjnej na warstwie ukrytej. \n",
    "# TODO: przejrzeć jakie są inne funkcje aktywacyjne\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając gotową architekturę sieci, musimy model \"skompilować\". W kerasie oznacza to ustalenie funkcji straty i algorytmu optymalizującego. My skorzystamy z *log lossa* (w kerasie `categorical_crossentropy`) i metody optymalizacji SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='categorical_crossentropy',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczenie modelu polega na wywałaniu metody `fit` - czyli dopasowania się do danych treningowych.  \n",
    "**TODO: przeczytać** https://keras.io/models/sequential/  \n",
    "Ważne: w przypadku klasyfikacji keras wymaga zawsze danych w postaci *one-hot encoding* - na szczęście nasze już są w tym formacie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=X, y=Y, epochs=20, verbose = 0, batch_size=600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "print('training accuracy: %.2f' % (np.mean(np.argmax(preds, axis=1) == np.argmax(Y, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że model wolno się uczy. Stwórzmy model od nowa (aby zresetować go do stanu początkowego) i sprawdźmy co się dzieje (parametr `verbose=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########\n",
    "########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas na zbudowanie modelu na rzeczywistych danych. Keras udostępnia sporo gotowych zbiorów - skorzystamy teraz z jednego z nich.   \n",
    "Zbiór `boston_housing` zawiera dane na temat 506 domów w bostonie. Wartością, którą chcemy przewidzieć jest mediana ceny domów w danej okolicy.  \n",
    "**TODO:** Dokładniejszy opis danych: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train_boston, Y_train_boston), (X_test_boston, Y_test_boston) = boston_housing.load_data()\n",
    "print(X_train_boston.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Przerywnik - o walidacji modeli**  \n",
    "Budując model, chcemy mieć informację czego możemy się po nim spodziewać pod kątem skuteczności. Procedura, którą stosowaliśmy wcześniej jest błędna - testowaliśmy model na tych samych obserwacjach, na któych model się uczył. Stosując model produkcyjnie, będziemy mu dawać obserwacje których nigdy nie miał okazji widzieć wcześniej, więc wypadałoby uwzględnić to podczas procedury testowania modelu. Stąd domyślny podział danych na dwie części."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# przykładowy wiersz\n",
    "X_train_boston[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: zbudować model bez żadnej warstwy ukrytej - tzn tylko wejście i wyjście. Zaproponować jakąś miarę błędu na zbiorze testowym i obliczyć ją.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates Mean Absolute Error \n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_boston_linear = Sequential()\n",
    "model_boston_linear.add(Dense(1, input_dim=13))\n",
    "model_boston_linear.add(Activation('linear'))\n",
    "\n",
    "model_boston_linear.compile(optimizer='sgd', loss=\"mean_squared_error\")\n",
    "\n",
    "model_boston_linear.fit(X_train_boston, Y_train_boston, epochs=20, batch_size=404, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, funkcja straty wybucha do nieskonczoności. Jeśli sprawdzicie wartość wag w modelu (**TODO**: model_boston_linear.get_weights()), zapewne też będą miały wartość `inf`.  \n",
    "**TODO**: burza mózgów - dlaczego tak się dzieje?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######\n",
    "\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Scaler():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def scale_train(self, X):\n",
    "        pass\n",
    "    \n",
    "    def scale_test(self, X):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = Scaler()\n",
    "X_train_boston_scaled = scaler.scale_train(X_train_boston)\n",
    "X_test_boston_scaled = scaler.scale_test(X_train_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_boston_linear = Sequential()\n",
    "model_boston_linear.add(Dense(1, input_dim=13))\n",
    "model_boston_linear.add(Activation('linear'))\n",
    "\n",
    "model_boston_linear.compile(optimizer='sgd', loss=\"mean_squared_error\")\n",
    "\n",
    "model_boston_linear.fit(X_train_boston_scaled, Y_train_boston, epochs=20, batch_size=404, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions_boston = model_boston_linear.predict(X_train_boston_scaled)\n",
    "print(MAE(y_pred=test_predictions_boston, y_true=Y_test_boston))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rozpoznawanie pisma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przejdziemy teraz do wykorzystania sieci neuronowych przy analizie obrazu. Będziemy zajmować się zbiorem MNIST, który zawiera zdjęcia ręcznie pisanych cyfr. Naszym zadaniem będzie nauczenie sieci rozpoznawania cyfr.  \n",
    "Najpierw musimy pobrać zbiór danych:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train_mnist, Y_train_mnist), (X_test_mnist, Y_test_mnist) = mnist.load_data()\n",
    "print(X_train_mnist.shape)\n",
    "print(Y_train_mnist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit = X_train_mnist[0]\n",
    "print(Y_train_mnist[0])\n",
    "plt.imshow(digit, interpolation = \"nearest\", cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: zbadaj, jak zapisywane są dane o odcieniach szarości w macierzy reprezentującej cyfrę, i zaproponuj sposób na sprowadzenie danych do formatu akceptowalnego przez sieć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_mnist = Sequential()\n",
    "model_mnist.add(Dense(200, input_dim=28*28))\n",
    "model_mnist.add(Activation('relu'))\n",
    "model_mnist.add(Dense(10))\n",
    "model_mnist.add(Activation('softmax'))\n",
    "\n",
    "model_mnist.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model_mnist.fit(X_train_mnist, to_categorical(Y_train_mnist), epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_mnist = model_mnist.predict(X_test_mnist_reshaped)\n",
    "print('test accuracy: %.2f' % (np.mean(np.argmax(preds_mnist, axis=1) == Y_test_mnist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czy na pewno nasz model nauczył się \"widzieć\" i rozpoznawać cyfry? Sprawdźmy co się stanie, jeśli każdą obserwację w zbiorze przemieszamy za pomocą tej samej permutacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffler = np.random.permutation(X_train_mnist_reshaped.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_mnist_shuffled = X_train_mnist_reshaped[:, shuffler]\n",
    "X_test_mnist_shuffled = X_test_mnist_reshaped[:, shuffler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit = X_train_mnist_reshaped[0].reshape((28, 28))\n",
    "print(Y_train_mnist[0])\n",
    "plt.imshow(digit, interpolation = \"nearest\", cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit = X_train_mnist_shuffled[0].reshape((28, 28))\n",
    "print(Y_train_mnist[0])\n",
    "plt.imshow(digit, interpolation = \"nearest\", cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_mnist_shuffled = Sequential()\n",
    "model_mnist_shuffled.add(Dense(200, input_dim=28*28))\n",
    "model_mnist_shuffled.add(Activation('relu'))\n",
    "model_mnist_shuffled.add(Dense(10))\n",
    "model_mnist_shuffled.add(Activation('softmax'))\n",
    "\n",
    "model_mnist_shuffled.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "model_mnist_shuffled.fit(X_train_mnist_shuffled, to_categorical(Y_train_mnist), epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okazuje się, że model nie działa w sposób analogiczny do tego, jak my postrzegamy świat. To co dla nas jest chmurą losowych punktów, dla modelu jest cyfrą. Wynika to z tej akurat konkretnie archutektury sieci - model nie bierze pod uwagę korelacji między pikselami leżącymi obok siebie, i traktuje każdy jako niezależną zmienną - co jest oczywiście założeniem zupełnie błędnym.\n",
    "\n",
    "**TODO (grube): poczytać (nawet pobieżnie) o sieciach (warstwach) konwolucyjnych.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Źródła, dodatkowe czytajki, zajawki:\n",
    "* https://www.coursera.org/learn/neural-networks - kurs \"ojca\" sieci neuronowych od podstaw  \n",
    "* http://cs231n.github.io/ - trochę bardziej zaawansowany  \n",
    "* http://www.asimovinstitute.org/neural-network-zoo/ - fajna ogólna opowieść\n",
    "* ogólnie coursera\n",
    "* http://cs231n.stanford.edu/vecDerivs.pdf - zostawiam też tu, dla przypomnienia\n",
    "* https://www.youtube.com/watch?v=qv6UVOQ0F44 - MarIO\n",
    "* https://www.youtube.com/watch?v=dqxqbvyOnMY - przetwarzanie obrazu za pomocą GAN-ów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general_p3]",
   "language": "python",
   "name": "conda-env-general_p3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
